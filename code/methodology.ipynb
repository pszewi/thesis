{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc75f8e5",
   "metadata": {},
   "source": [
    "# Methodology and Analysis Notebook\n",
    "#### In this notebook I note my methods and ideas as I go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1f860",
   "metadata": {},
   "source": [
    "#### Experiment-setup:\n",
    "\n",
    "I am trying to investigate whether firms can utilize greenwashing as a profitable strategy. In order to do that I want to create a measure of greenwashing by following *(Lagasio, 2024)*. Furthermore, I will utilize a natural experiment (DiD) to search for causality.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Experiment notes:\n",
    "* Use a DiD with continuous treatment to see whether greenwashing more makes you profit more\n",
    "* For applying treatment, use the level of greenwashing from 2014/2015\n",
    "    * The justification is that in 2013/2014 the previous IPCC report was released \n",
    "    * Since that created a bit of buzz, it may have allowed firms to start greenwashing\n",
    "    <div>\n",
    "    <img src=\"../img/ipcc_trends_2004-2025.png\" width=\"600\"/>\n",
    "    </div>\n",
    "\n",
    "* For the shock, use September 2019, as that's when there was a lot of buzz around another IPCC report and Fridays For Future movement\n",
    "    <div>\n",
    "    <img src=\"../img/climate_trends_2004_2022.png\" width=\"600\"/>\n",
    "    </div>\n",
    "\n",
    "* use cumulative abnormal returns as the outcome variable \n",
    "* use sales as a secondary outcome variable\n",
    "\n",
    "----\n",
    "#### Some links:\n",
    "* [IPPC Wikipedia Page](https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change)\n",
    "* [6th IPCC Assessment](https://en.wikipedia.org/wiki/IPCC_Sixth_Assessment_Report)\n",
    "* [IPCC Special Report from 2019](https://en.wikipedia.org/wiki/Special_Report_on_Climate_Change_and_Land)\n",
    "* [Fridays For Future movement Wiki](https://en.wikipedia.org/wiki/Fridays_for_Future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e79fe0",
   "metadata": {},
   "source": [
    "Total Return Index from datastream:\n",
    "RI - Total Return Index\n",
    "Explorers\t\n",
    "Equities » Key Datatypes\n",
    "Equities » Datastream » Time Series » Pricing\n",
    "Actions\tAdd to My Selections\n",
    "Notes\t\n",
    "The Return Index shows the growth in value of a security over a specified period, assuming that dividends are re-invested to purchase additional shares of the security at the closing price (P) on the dividend ex-date.\n",
    "\n",
    "For all markets except Canada and the US, dividend payment data (DDE) is only available from 1988, for securities listed before this point the return index is calculated using the dividend yield (DY). This method adds an increment of 1/260th part of the dividend yield to the price each weekday. There are assumed to be 260 weekdays in a year, market holidays are ignored.\n",
    "\n",
    "Method 1 (using annualised dividend yield)\n",
    "\n",
    "RI on the BDATE =100, then:\n",
    "\n",
    "cid:image001.gif@01CC34D5.05D81F30\n",
    "\n",
    "Where:\n",
    "\n",
    "cid:image002.gif@01CC34D5.05D81F30 = return index on day t\n",
    "\n",
    "cid:image003.gif@01CC34D5.05D81F30= return index on previous day\n",
    "\n",
    "cid:image004.gif@01CC34D5.05D81F30 = price index on day t\n",
    "\n",
    "cid:image005.gif@01CC34D5.05D81F30 = price index on previous day\n",
    "\n",
    "cid:image006.gif@01CC34D5.05D81F30 = dividend yield % on day t\n",
    "\n",
    " N = number of working days in the year (taken to be 260)\n",
    "\n",
    "For securities listed before 1988 the RI calculation switches from the dividend yield method to using the dividend payment data, for example the first recorded dividend for BP is 15/08/88 – on this date the RI calculation switches from the dividend yield method to using the dividend payment data. This method represents a more accurate measure of the security’s growth in which the discrete quantity of dividend paid is added to the price on the ex-date of the payment\n",
    "\n",
    "Method 2 (using dividend payment data)\n",
    "\n",
    "RI on the BDATE =100, then:\n",
    "\n",
    " cid:image007.gif@01CC34D5.05D81F30\n",
    "\n",
    " except when t = ex-date of the dividend payment Dt then:\n",
    "\n",
    "cid:image011.gif@01CC34D6.0623B1B0\n",
    "\n",
    "Where:\n",
    "\n",
    " cid:image008.gif@01CC34D5.05D81F30 = price on ex-date\n",
    "\n",
    "= price on previous day\n",
    "\n",
    " cid:image010.gif@01CC34D5.05D81F30 = dividend payment associated with ex-date t\n",
    "\n",
    "The calculation ignores tax and re-investment charges.\n",
    "\n",
    "Canadian and US securities are not affected by the dual calculation method, dividend payment data is available from 1973 – the Datastream market inception date for both markets.\n",
    "\n",
    "Securities listed after 1988 automatically use RI calculation method 2, dividend payment data.\n",
    "\n",
    "Adjusted closing prices are used throughout to determine price index and hence return index.\n",
    "\n",
    "Note: where the dividend payment data history contains a mixture of gross and net dividends the annualised dividend yield (method 1 above) is used in order to achieve a consistent growth measure. The net and gross markers can be identified using the datatype DTAX (tax marker). To display the total return using the dividend payment data (method 2) in these cases, the alternative total return datatype RZ (Return Index - As Paid) may be used. RZ uses the dividend payment data calculation method irrespective of the tax markers.\n",
    "\n",
    "For UK companies the RI includes a tax credit on the dividend until it was abolished in April 2004. Prior to that time dividends as announced by the company are grossed up to include to the credit in the RI calculation. The rate used varies over time, the last rate being 10% in the period April 1999 to April 2004. To see a return index measure which does not include tax credits, the datatype RN (Return Index – Net) should be used. The RN calculation is the same as RI except the dividends used are as announced by the company and not grossed up for the tax credits. It follows that since April 2004 the performance of RI and RN for UK securities is the same. RN is available for UK securities only.\n",
    "\n",
    "See also:\n",
    "\n",
    "PI\tPrice Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77006b17",
   "metadata": {},
   "source": [
    "#### Greenwashing Indicator\n",
    "\n",
    "First reading in pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce218eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16e8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data_greenwashing = pd.read_excel('../data/LSEG data/matched_final.xlsx', sheet_name='companies')\n",
    "data_returns = pd.read_excel('../data/LSEG data/matched_final.xlsx', sheet_name='indicators_1')\n",
    "data_indices = pd.read_excel('../data/LSEG data/matched_final.xlsx', sheet_name='INDICES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d81b70",
   "metadata": {},
   "source": [
    "Adding some more pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /////////////////////////////////////\n",
    "#       expanding\n",
    "# /////////////////////////////////////\n",
    "\n",
    "data['year_lists'] = data['year_lists'].apply(eval)\n",
    "\n",
    "# Expand each list entry into its own row\n",
    "data = data.explode('year_lists', ignore_index=True)\n",
    "\n",
    "data['year'] = data['year_lists'].str.extract(r'(\\d+)')\n",
    "data['year'] = data['year'].astype(float)\n",
    "\n",
    "print(data.value_counts('year'))\n",
    "\n",
    "obs_2014 = data[data['year']==2014]\n",
    "\n",
    "# # ////////////////////////////////////////////////////////\n",
    "# # NOTE HOW MANY FIRMS WITH REPORTS IN THE YEARS I NEED\n",
    "g = data[(data[\"year\"]>2016) & (data[\"year\"]<2022)].groupby(\"name\").count()\n",
    "print(g.value_counts(\"industry\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da270d",
   "metadata": {},
   "source": [
    "Text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ////////////////////////////////////////////////////////////\n",
    "#       EXTRACTING TEXT FROM PDFS\n",
    "# ////////////////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "pdf_information = data[[\"name\"]]\n",
    "pdf_information[\"first_page\"] = pd.NA\n",
    "pdf_information[\"second_page\"] = pd.NA\n",
    "\n",
    "result = pd.DataFrame({\"name\":[],  \n",
    "                       \"title_page\":[], \n",
    "                       \"second_page\":[]})\n",
    "\n",
    "for index,row in pdf_information[0:11].iterrows():\n",
    "    \n",
    "    company_name = row[\"name\"].lower().replace(\" \", \"_\")\n",
    "        \n",
    "    if any(i in company_name for i in (\"?\", \"|\")):\n",
    "        company_name = company_name.replace(\"?\", \"\")\n",
    "        company_name = company_name.replace(\"|\", \"\")\n",
    "    \n",
    "    company_dir = f\"C:/Users/Jakub/OneDrive - Tilburg University/thesis data/responsibility reports/{company_name}\"\n",
    "    \n",
    "    list_of_paths = [company_dir + f\"/{file}\" for file in os.listdir(company_dir)]\n",
    "    \n",
    "    temp_df = pd.DataFrame({\"name\":[row[\"name\"]]*len(list_of_paths),\n",
    "                            \"title_page\":[None]*len(list_of_paths), \n",
    "                            \"second_page\":[None]*len(list_of_paths)})\n",
    "    \n",
    "    i=0\n",
    "    for file in list_of_paths:    \n",
    "        with pymupdf.open(file) as doc:\n",
    "            title_page = doc[0].get_text()\n",
    "            second_page = doc[1].get_text()\n",
    "            \n",
    "            temp_df.iat[i, 1] = title_page\n",
    "            temp_df.iat[i, 2] = second_page\n",
    "            i+=1\n",
    "    \n",
    "    \n",
    "    result = pd.concat([result, temp_df])    \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
