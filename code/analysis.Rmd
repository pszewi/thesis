---
title: "Data Analysis for Thesis"
author: "Jakub Przewoski"
date: "2025-04-28"
output: html_document
---

# Description
In this file I will be writing down the methodological notes for my thesis and I will also compute here my experiment. 



## Experiment-setup:
I am trying to investigate whether firms can utilize greenwashing as a profitable strategy. In order to do that I want to create a measure of greenwashing by following *(Lagasio, 2024)*. Furthermore, I will utilize a natural experiment (DiD) to search for causality.


## Experiment notes:
* Use a DiD with continuous treatment to see whether greenwashing more makes you profit more
* For applying treatment, use the level of greenwashing from 2017/2018
    * The justification is that I need to assume that the treatment level was constant which implies that I should have as little time as possible between the treatment assignment and my shock 
    * I have computed both the 2017 and the 2018 Greenwashing index.
* For the shock, use September 2019, as that's when there was a lot of buzz around another IPCC report and Fridays For Future movement
    * use cumulative abnormal returns as the outcome variable 
    * use sales as a secondary outcome variable

Some pictures showing google trends around specific queries around that time:

<div>
<img src="../images/ipcc_trends_2008_2021.png" width="600"/>
</div>


<div>
<img src="../images/climate_trends_2004_2022.png" width="600"/>
</div>


----

## Some links:
* [IPPC Wikipedia Page](https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change)
* [6th IPCC Assessment](https://en.wikipedia.org/wiki/IPCC_Sixth_Assessment_Report)
* [IPCC Special Report from 2019](https://en.wikipedia.org/wiki/Special_Report_on_Climate_Change_and_Land)
* [Fridays For Future movement Wiki](https://en.wikipedia.org/wiki/Fridays_for_Future)
* [List of school climate strikes](https://en.wikipedia.org/wiki/List_of_school_climate_strikes)


----

# Code

## Loading libraries


```{r, libs, message = FALSE}
library(httpgd)
library(tidyverse)
library(data.table)
library(ggplot2)
library(fixest)
library(stargazer)
```

## Loading Data

First loading here data at the weekly frequency as it seems the most reasonable.

```{r,data, message = FALSE}
company_characteristics <- read_csv("data/output/company_characteristics.csv")
greenwashing_ind_2017  <- read_csv("data/text_processing/greenwashing_ind_2017.csv")
greenwashing_ind_2018  <- read_csv("data/text_processing/greenwashing_ind_2018.csv")


data_abnormal_returns_w <- read_csv("data/output/data_abnormal_returns_w.csv")
data_abnormal_returns_d <- read_csv("data/output/data_abnormal_returns_d.csv")
data_sales  <- read_csv("data/output/data_sales.csv")

```

Adjusting the universal data (needed for all regressions)

```{r, char_green_data}

# get rid of an observation with a missing indicator and likely faulty outliers
greenwashing_ind_2017 <- greenwashing_ind_2017 %>%
    filter(NAME != "Genmab A/S")  %>%
    arrange(CLIMATE_REL)
# View(greenwashing_ind_2017)

# get rid of an observation with a missing indicator and likely faulty outliers
greenwashing_ind_2018 <- greenwashing_ind_2018 %>%
    filter(!(NAME %in% c("Genmab A/S", "Ashland Inc.", "Fletcher Building Limited", "Ethan Allen Interiors Inc.",
                         "Equifax Inc.", "Sagicor Financial Company Ltd.", "Korn/Ferry International",
                         "Spark NZ", "Covestro AG")), CLIMATE_REL > 2)  %>%
    mutate(GREEN_IND_2 = NON_SPEC / CLIMATE_REL)
# View(greenwashing_ind_2018)


company_characteristics  <- company_characteristics  %>% filter(YEAR == 2018)
company_characteristics_2018 <- merge(company_characteristics, greenwashing_ind_2018,
                                      by.x = "NAME_SCRAPED", by.y = "NAME") %>%
    select(c("TYPE", "NAME", "BOURSE_NAME", "ICB_INDUSTRY_NAME", "ICB_SECTOR_NAME", "CTRY_OF_DOM_NAME",
             "CTRY_OF_INC_NAME", "EMPLOYEES", "YEAR", "GREEN_IND")) %>%
    filter(!duplicated(NAME))

```

## Descriptive statistics

```{r, desc_stats, asis=TRUE}


desc_stats <- company_characteristics_2018 %>%
    mutate(T_ = ifelse(GREEN_IND > mean(GREEN_IND), 1, 0))

table(desc_stats$T_, desc_stats$ICB_INDUSTRY_NAME)
table(desc_stats$T_, desc_stats$CTRY_OF_DOM_NAME)
table(desc_stats$T_, desc_stats$BOURSE_NAME)
table(desc_stats$T_, desc_stats$EMPLOYEES)


# stargazer(company_characteristics_2018$ICB_INDUSTRY_NAME)


library(ggplot2)


ggplot(data = desc_stats,
       #    aes(x = factor(ICB_INDUSTRY_NAME))) +
       aes(x = factor(ICB_INDUSTRY_NAME), fill = factor(T_))) +
    # geom_bar(fill   = "steelblue", color  = "black", width  = 0.7) +
    geom_bar(position = "fill", width = 0.7) +
    labs(
         x     = "Category",
         y     = "Count",
         title = "Distribution of Categories", 
         fill="Treatment") +
    theme_bw(base_size = 14) +
    theme(
          panel.grid.major    = element_blank(),
          panel.grid.minor    = element_blank(),
          axis.text.x         = element_text(angle = 45, hjust = 1),
          plot.title          = element_text(hjust = 0.5, face = "bold"),
          axis.title          = element_text(face = "bold"))



library(gtsummary)

tbl_ltx = desc_stats %>%
    select(CTRY_OF_DOM_NAME, T_) %>%
    tbl_summary(
                by = T_,
                statistic = list(CTRY_OF_DOM_NAME ~ "{n} ({p}%)")) %>%
    add_overall() %>%
    modify_header(
                  label     = "Number of ...",
                  all_stat_cols() ~ "{level} (N = {n})") %>%
    modify_table_body(~.x %>% relocate(stat_0, stat_2, stat_1, .after = label))


tbl_ltx %>%
  as_kable(
    format    = "latex",
    booktabs  = TRUE
  ) 

# number of reports per year
tbl_yrs = company_characteristics %>%
    group_by(YEAR) %>%
    summarize(num = n()) %>%
    arrange(desc(num))

as_gtsummary(tbl_yrs) %>%
  as_kable(
    format    = "latex",
    booktabs  = TRUE
  ) 

```


## Stock data

#### Weekly 

Merging the data into a single dataset for regressing
```{r, merge_w}

# weekly
reg_data_w <- merge(company_characteristics_2017, data_abnormal_returns_w, by = "NAME")  %>%
    rename("CTRY_OF_DOM_NAME" = "CTRY_OF_DOM_NAME.x") %>%
    select(-CTRY_OF_DOM_NAME.y) %>%
    mutate(
        ABN_RET_LOG = STOCK_LOG_RETURN - NORMAL_RETURN,
        T_ = ifelse(GREEN_IND > mean(GREEN_IND), 1, 0),
        POST = ifelse(DATE >= as.Date("2019-08-08"), 1, 0),
        TxPOST = as.factor(T_ * POST),
        DATE = as.Date(DATE),
        DATE_factor = factor(DATE),
        NAME_factor = factor(NAME)
    )

reg_data_w <- reg_data_w  %>%
    group_by(NAME) %>%
    filter(!(is.na(ABN_RET_LOG))) %>%
    mutate(CAR = cumsum(ABN_RET_LOG)) %>%
    ungroup()  %>%
    filter(DATE < as.Date("2019-09-08")) %>%
    arrange(NAME, DATE)


```

## CAR Evolution per group

```{r, trend_evo_w}

car_graph_w  <- reg_data_w %>%
    group_by(T_, DATE) %>%
    summarize(mean_car = mean(CAR))

head(car_graph_w)


ggplot() + geom_line(data = car_graph_w, aes(x = DATE, y = mean_car, color = as.factor(T_)))

```

#### DiD
```{r, did_w}

print("------------")
model <- feols(CAR ~  TxPOST | NAME_factor + DATE_factor,
               data = reg_data_w, cluster = ~ NAME_factor)
summary(model)


```


## Event study regression
```{r, event_study_w}
event_date_1 <- as.Date("2019-08-09")
event_date_2 <- as.Date("2019-09-20")

reg_data_w_eve <- reg_data_w  %>%
    mutate(
        TimeTo_T_1 = as.numeric(difftime(reg_data_w$DATE, event_date_1, units = "weeks")),
        TimeTo_T_2 = as.numeric(difftime(reg_data_w$DATE, event_date_2, units = "weeks"))
    )

# View(reg_data_w_eve)

# ------------ FIRST SHOCK
mod_twfe <- feols(CAR ~ i(TimeTo_T_1, T_, ref = -1) | DATE_factor + NAME_factor,
                  cluster = ~NAME_factor, data = reg_data_w_eve)

iplot(mod_twfe,
      xlab = "Time to treatment",
      main = "Event study: Treatment (TWFE)")


# # ----------- SECOND SHOCK
# reg_data_w_eve <- reg_data_w_eve  %>%
#     filter(DATE > as.Date("2019-09-10"))

# mod_twfe <- feols(CAR ~ i(TimeTo_T_2, T_, ref = -1) | DATE_factor + NAME_factor,
#                   cluster = ~NAME_factor, data = reg_data_w_eve)

# iplot(mod_twfe,
#       xlab = "Time to treatment",
#       main = "Event study: Treatment (TWFE)")
```


## Diff-in-Diff regression

#### Daily



```{r, merge_d}

# daily
reg_data_d <- merge(company_characteristics_2017, data_abnormal_returns_d, by = "NAME")  %>%
    rename("CTRY_OF_DOM_NAME" = "CTRY_OF_DOM_NAME.x") %>%
    select(-CTRY_OF_DOM_NAME.y) %>%
    arrange(NAME, DATE) %>%
    mutate(
        ABN_RET_LOG = STOCK_LOG_RETURN - NORMAL_RETURN,
        T_ = ifelse(GREEN_IND > mean(GREEN_IND), 1, 0),
        POST_1 = ifelse(DATE >= as.Date("2019-08-08"), 1, 0),
        POST_2 = ifelse(DATE >= as.Date("2019-09-20"), 1, 0),
        TxPOST_1 = as.factor(T_ * POST_1),
        TxPOST_2 = as.factor(T_ * POST_2),
        DATE = as.Date(DATE),
        DATE_factor = factor(DATE),
        NAME_factor = factor(NAME)
    )

# View(reg_data_d)

reg_data_d <- reg_data_d  %>%
    group_by(NAME) %>%
    filter(!(is.na(ABN_RET_LOG))) %>%
    mutate(CAR = cumsum(ABN_RET_LOG)) %>%
    ungroup() %>%
    filter(DATE > as.Date("2019-07-15"), DATE < as.Date("2019-10-01")) %>%
    arrange(NAME, DATE)


```

## CAR Evolution per group

```{r, trend_evo_d}

car_graph_d  <- reg_data_d %>%
    group_by(T_, DATE) %>%
    summarize(mean_car = mean(CAR))

head(car_graph_d)


ggplot() + geom_line(data = car_graph_d, aes(x = DATE, y = mean_car, color = as.factor(T_)))

```

#### DiD
```{r, did_d}

print("------------")
model <- feols(CAR ~  TxPOST_1 | NAME_factor + DATE_factor,
               data = reg_data_d, cluster = ~ NAME_factor)
summary(model)


```


## Event study regression
```{r, event_study_d}
event_date_1 <- as.Date("2019-08-08")
event_date_2 <- as.Date("2019-09-20")

reg_data_d_eve <- reg_data_d  %>%
    mutate(
        TimeTo_T_1 = as.numeric(difftime(reg_data_d$DATE, event_date_1, units = "days")),
        TimeTo_T_2 = as.numeric(difftime(reg_data_d$DATE, event_date_2, units = "days"))
    )

# View(reg_data_d_eve)

# ------------ FIRST SHOCK
mod_twfe <- feols(CAR ~ i(TimeTo_T_1, T_, ref = -1) | DATE_factor + NAME_factor,
                  cluster = ~NAME_factor, data = reg_data_d_eve)

iplot(mod_twfe,
      xlab = "Time to treatment",
      main = "Event study: Treatment (TWFE)")


# ----------- SECOND SHOCK
reg_data_d_eve <- reg_data_d_eve  %>%
    filter(DATE > as.Date("2019-09-10"))

mod_twfe <- feols(CAR ~ i(TimeTo_T_2, T_, ref = -1) | DATE_factor + NAME_factor,
                  cluster = ~NAME_factor, data = reg_data_d_eve)

iplot(mod_twfe,
      xlab = "Time to treatment",
      main = "Event study: Treatment (TWFE)")
```


## Sales data

```{r, merge_sales}
data_sales  <- data_sales  %>%
    filter(DATE != "2010 Q1")

reg_data_sales <- merge(company_characteristics_2017, data_sales, by = "TYPE") %>%
    arrange(NAME.y, DATE)  %>%
    select(-YEAR.x, -YEAR.y, -QUARTER, -NAME.x)  %>%
    rename(NAME = NAME.y)  %>%
    group_by(NAME) %>%
    mutate(LOG_SALES_DIFF_4 = LOG_SALES_DIFF - lag(LOG_SALES_DIFF, 4))  %>%
    ungroup() %>%
    mutate(
        T_ = ifelse(GREEN_IND > mean(GREEN_IND), 1, 0),
        POST_1 = ifelse(DATE >= "2019 Q3", 1, 0),
        TxPOST = as.factor(T_ * POST_1),
        DATE_factor = factor(DATE),
        NAME_factor = factor(NAME)
    )  %>%
    filter(DATE >= "2018 Q1")

# View(reg_data_sales)

nrow(unique(reg_data_sales[reg_data_sales$T_ == 1, "NAME"]))
nrow(unique(reg_data_sales[reg_data_sales$T_ == 0, "NAME"]))

```



#### DiD on sales data
```{r, did_sales}
library(zoo)


print("------------")
model <- feols(LOG_SALES_DIFF_4 ~ TxPOST | NAME_factor + DATE_factor,
               data = reg_data_sales, cluster = ~ NAME_factor)
summary(model)

event_Q <- "2019 Q3" # nolint

reg_data_eve <- reg_data_sales %>%
    mutate(
        # convert your dates to yearqtr
        DATE_Q   = as.yearqtr(DATE),
        event_Q  = as.yearqtr(event_Q),
        # numeric difference in quarters
        TimeTo_Q = as.numeric(DATE_Q - event_Q)
    )

# View(reg_data_eve)
mod_twfe <- feols(LOG_SALES_DIFF_4 ~ i(TimeTo_Q, T_, ref = -0.25) | DATE_factor + NAME_factor,
                  cluster = ~NAME_factor, data = reg_data_eve)

iplot(mod_twfe,
      xlab = "Time to treatment",
      main = "Event study: Treatment (TWFE)")

summary(mod_twfe)

```

If a company makes specific claims in their reports they would probably make them in marketing - better perceived by consumers?
Think about different justifications, e.g. reports look at the past years, 
companies make tv commercials that can include sustainability information


