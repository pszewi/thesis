---
title: "Data Analysis for Thesis"
author: "Jakub Przewoski"
date: "2025-04-28"
output: html_document
---

# Description
In this file I will be writing down the methodological notes for my thesis and I will also compute here my experiment. 



## Experiment-setup:
I am trying to investigate whether firms can utilize greenwashing as a profitable strategy. In order to do that I want to create a measure of greenwashing by following *(Lagasio, 2024)*. Furthermore, I will utilize a natural experiment (DiD) to search for causality.


## Experiment notes:
* Use a DiD with continuous treatment to see whether greenwashing more makes you profit more
* For applying treatment, use the level of greenwashing from 2017/2018
    * The justification is that I need to assume that the treatment level was constant which implies that I should have as little time as possible between the treatment assignment and my shock 
    * I have computed both the 2017 and the 2018 Greenwashing index.
* For the shock, use September 2019, as that's when there was a lot of buzz around another IPCC report and Fridays For Future movement
    * use cumulative abnormal returns as the outcome variable 
    * use sales as a secondary outcome variable

Some pictures showing google trends around specific queries around that time:

<div>
<img src="../images/ipcc_trends_2008_2021.png" width="600"/>
</div>


<div>
<img src="../images/climate_trends_2004_2022.png" width="600"/>
</div>


----

## Some links:
* [IPPC Wikipedia Page](https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change)
* [6th IPCC Assessment](https://en.wikipedia.org/wiki/IPCC_Sixth_Assessment_Report)
* [IPCC Special Report from 2019](https://en.wikipedia.org/wiki/Special_Report_on_Climate_Change_and_Land)
* [Fridays For Future movement Wiki](https://en.wikipedia.org/wiki/Fridays_for_Future)
* [List of school climate strikes](https://en.wikipedia.org/wiki/List_of_school_climate_strikes)


----

# Code

## Loading libraries


```{r, libs, message = FALSE}
library(httpgd)
library(tidyverse)
library(data.table)
library(ggplot2)
library(fixest)

```

## Loading Data

First loading here data at the weekly frequency as it seems the most reasonable.

```{r,data, message = FALSE}

# NOTE: MAKE SURE THAT THE DATES ARE PARSED CORRECTLY


data_abnormal_returns_w <- read_csv("data/output/data_abnormal_returns_w.csv")
company_characteristics <- read_csv("data/output/company_characteristics.csv")
greenwashing_ind_2017  <- read_csv("data/text_processing/greenwashing_ind_2017.csv")

```

Merging the data into a single dataset for regressing
```{r, merge}
# get rid of an observation with a missing indicator and likely faulty outliers
greenwashing_ind_2017 <- greenwashing_ind_2017 %>%
    filter(NAME != "Genmab A/S", GREEN_IND < 0.96)

company_characteristics  <- company_characteristics  %>% filter(YEAR == 2017)
company_characteristics_2017 <- merge(company_characteristics, greenwashing_ind_2017,
                                      by.x = "NAME_SCRAPED", by.y = "NAME") %>%
    select(c("NAME", "BOURSE_NAME", "ICB_INDUSTRY_NAME", "ICB_SECTOR_NAME", "CTRY_OF_DOM_NAME",
             "CTRY_OF_INC_NAME", "EMPLOYEES", "YEAR", "GREEN_IND")) %>%
    filter(!duplicated(NAME))

reg_data <- merge(company_characteristics_2017, data_abnormal_returns_w, by = "NAME")  %>%
    rename("CTRY_OF_DOM_NAME" = "CTRY_OF_DOM_NAME.x") %>%
    select(-CTRY_OF_DOM_NAME.y) %>%
    mutate(
        ABN_RET_LOG = STOCK_LOG_RETURN - NORMAL_RETURN,
        T_ = ifelse(GREEN_IND > mean(GREEN_IND), 1, 0),
        POST = ifelse(DATE > as.Date("2019-09-20"), 1, 0),
        TxPOST = as.factor(T_ * POST),
        DATE = as.Date(DATE),
        DATE_factor = factor(DATE),
        NAME_factor = factor(NAME)
    )

reg_data <- reg_data  %>%
    group_by(NAME) %>%
    filter(!(is.na(ABN_RET_LOG))) %>%
    mutate(CAR = cumsum(ABN_RET_LOG)) %>%
    ungroup()

# View(reg_data)

test <- reg_data %>%
    filter(DATE > as.Date("2019-08-01"), DATE < as.Date("2019-11-01")) %>%
    arrange(NAME, DATE)

# View(test)
```

## CAR Evolution per group

```{r, trend_graph}

car_graph  <- test %>%
    group_by(T_, DATE) %>%
    summarize(mean_car = mean(CAR))

head(car_graph)


ggplot() + geom_line(data=car_graph, aes(x = DATE, y = mean_car, color = as.factor(T_)))

```

## Balance table

```{r, balance_tab}
#
```

## **IMPORTANT**

* Make sure that data is correctly sorted
* Investigate why different results from results in python
* Make a balance table by checking whether treatment correlated with any company_characteristics
* Read the goddamn papers on diff-in-diff to understand it better!
* Plot the average CAR returns for Treated/non-treated
* Make an event study per group!




## Event study regression
```{r, event_study}
event_date <- as.Date("2019-09-20")

test_eve  <- test  %>%
    mutate(
        TimeTo_T = as.numeric(difftime(test$DATE, event_date, units = "weeks"))

    )

mod_twfe <- feols(CAR ~ i(TimeTo_T, T_, ref = -1) | DATE_factor + NAME_factor,
                  cluster = ~NAME_factor, data = test_eve)

iplot(mod_twfe,
      xlab = "Time to treatment",
      main = "Event study: Staggered treatment (TWFE)")

# summary(mod_twfe)
```

## Diff-in-Diff regression

```{r, did}
test_5periods <- test %>%
    filter(DATE > as.Date("2019-08-23"), DATE < as.Date("2019-10-18"))

print("------------")
model <- feols(CAR ~ TxPOST | NAME_factor + DATE_factor, data = test_5periods, cluster = ~NAME_factor)
summary(model)


```




